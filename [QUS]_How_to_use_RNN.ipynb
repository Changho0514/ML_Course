{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[QUS] How_to_use_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Changho0514/web1/blob/main/%5BQUS%5D_How_to_use_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence를 처리하기 위한 RNN \n",
        "\n",
        "1. 주어진 데이터를 RNN에 넣을 수 있는 형태로 만듭니다.\n",
        "2. 기본적인 RNN 사용법 및 적용법을 익힙니다.\n",
        "3. LSTM, GRU의 사용법 및 적용법을 익힙니다."
      ],
      "metadata": {
        "id": "JFC0R_4A1iU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0IYwIC091UT9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "n8JGZ6vf3ZfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 sample data를 확인해봅시다.  \n",
        "전체 단어 수와 pad token의 id도 아래와 같습니다."
      ],
      "metadata": {
        "id": "etKgmrJv3dat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 100\n",
        "pad_id = 0\n",
        "\n",
        "data = [\n",
        "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n",
        "  [62,76,79,66,32],\n",
        "  [93,77,16,67,46,74,24,70],\n",
        "  [19,83,88,22,57,40,75,82,4,46],\n",
        "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n",
        "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n",
        "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n",
        "  [94,21,79,24,3,86],\n",
        "  [80,80,33,63,34,63],\n",
        "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n",
        "]"
      ],
      "metadata": {
        "id": "oGR8GqPn1x9k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "QMPRPFHRo1kH",
        "outputId": "a1bdadd1-895f-4185-948a-d53deb324b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[85, 14, 80, 34, 99, 20, 31, 65, 53, 86, 3, 58, 30, 4, 11, 6, 50, 71, 74, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding 처리를 해주면서 padding 전 길이도 저장합니다."
      ],
      "metadata": {
        "id": "2qPOGgoh3gYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = len(max(data, key=len))\n",
        "print(f\"Maximum sequence length: {max_len}\")\n",
        "\n",
        "valid_lens = []\n",
        "for i, seq in enumerate(tqdm(data)):\n",
        "  valid_lens.append(len(seq))\n",
        "  if len(seq) < max_len:\n",
        "    data[i] = seq + [pad_id] * (max_len - len(seq))"
      ],
      "metadata": {
        "id": "l5ObMr393euW",
        "outputId": "f75069ef-5842-48d6-e3f2-e2eaa986bc43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence length: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 42755.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)\n",
        "print(valid_lens)"
      ],
      "metadata": {
        "id": "JO9yk5KH3skJ",
        "outputId": "eea0c860-786c-4355-f0c2-884e11e7a75e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[85, 14, 80, 34, 99, 20, 31, 65, 53, 86, 3, 58, 30, 4, 11, 6, 50, 71, 74, 13], [62, 76, 79, 66, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [93, 77, 16, 67, 46, 74, 24, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [19, 83, 88, 22, 57, 40, 75, 82, 4, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [70, 28, 30, 24, 76, 84, 92, 76, 77, 51, 7, 20, 82, 94, 57, 0, 0, 0, 0, 0], [58, 13, 40, 61, 88, 18, 92, 89, 8, 14, 61, 67, 49, 59, 45, 12, 47, 5, 0, 0], [22, 5, 21, 84, 39, 6, 9, 84, 36, 59, 32, 30, 69, 70, 82, 56, 1, 0, 0, 0], [94, 21, 79, 24, 3, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [80, 80, 33, 63, 34, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [87, 32, 79, 65, 2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80, 0, 0]]\n",
            "[20, 5, 8, 10, 15, 18, 17, 6, 6, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# B: batch size, L: maximum sequence length\n",
        "batch = torch.LongTensor(data)  # (B, L)\n",
        "batch_lens = torch.LongTensor(valid_lens)  # (B)"
      ],
      "metadata": {
        "id": "ckjoQ4Hv3wi9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch.shape"
      ],
      "metadata": {
        "id": "FLZ0T1c233eD",
        "outputId": "acc46d85-457d-4806-8857-be2fea0bda15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_lens, sorted_idx = batch_lens.sort(descending=True)\n",
        "batch = batch[sorted_idx]"
      ],
      "metadata": {
        "id": "zT1J4yD16HLS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch)\n",
        "print(batch_lens)"
      ],
      "metadata": {
        "id": "4m16vljl6Iem",
        "outputId": "f696f632-585f-493a-ef4f-b3baec4d3f1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
            "         74, 13],\n",
            "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
            "          0,  0],\n",
            "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
            "          0,  0],\n",
            "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
            "          0,  0],\n",
            "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN 사용해보기"
      ],
      "metadata": {
        "id": "egmXWzVx37ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN에 넣기 전 word embedding을 위한 embedding layer를 만듭니다."
      ],
      "metadata": {
        "id": "Td9xwbbj4ABX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 256\n",
        "\n",
        "## TODO ##\n",
        "embedding = nn.Embedding(vocab_size, embedding_size) # (단어들 갯수, word의 vector차원)\n",
        "\n",
        "# d_w: embedding size\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)"
      ],
      "metadata": {
        "id": "dbtmueDK35xw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch.shape"
      ],
      "metadata": {
        "id": "YlSTCJCcqUeK",
        "outputId": "0952cf6d-9b2c-4e6a-96b6-ac1b5b7486de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각각의 토큰에 대해서 vector로 만들어 준 것 \n",
        "batch_emb.shape"
      ],
      "metadata": {
        "id": "7ccQfeYW8HTM",
        "outputId": "a0a1aa56-0272-4b88-d140-fbec80787f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN 모델 및 초기 hidden state를 정의\n",
        "\n",
        "- batch_emb 변수를 RNN에 넣을 예정입니다.\n",
        "- torch 공식 문서를 참조하여, RNN 모델을 정의해보세요. \n",
        "- input size는 어떻게 되어야 하나요?"
      ],
      "metadata": {
        "id": "PnBnduU-4GXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "N, L H_in = batch_emb.shape\n"
      ],
      "metadata": {
        "id": "5ipyJfsuKYDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 512  # RNN의 hidden size\n",
        "num_layers = 1  # 쌓을 RNN layer의 개수\n",
        "num_dirs = 1  # 1: 단방향 RNN, 2: 양방향 RNN\n",
        "\n",
        "rnn = nn.RNN(\n",
        "    # TODO #\n",
        "    input_size = embedding_size,\n",
        "    hidden_size = hidden_size,\n",
        "    num_layers = num_layers,\n",
        "    bidirectional = True if num_dirs > 1 else False,\n",
        "    batch_first = True # batch가 가장 앞으로 나오게 되어있다. \n",
        ")\n",
        "\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"
      ],
      "metadata": {
        "id": "2RaWZKSI4Gqd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "output, h_n = rnn(batch_emb, h_0)\n",
        "이렇게 넣으면 안된다.\n",
        "batch_emb.shape은 batch가 제일 먼저 나온다  \n",
        "batch_first = False라고 하면 batch_size가 가장 앞에 나와야 함  \n",
        "따라서 \n",
        "output, h_n = rnn(batch_emb.reshape(L, N, H_in), h_0) 이런식으로 나와야 사용할 수 있다"
      ],
      "metadata": {
        "id": "pd1RKFaQKq1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vanilla RNN 활용법**"
      ],
      "metadata": {
        "id": "Q9KD-L5YC4YH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN에 batch data를 넣으면 아래와 같이 2가지 output을 얻습니다.\n",
        "\n",
        "\n",
        "*   `hidden_states`: 각 time step에 해당하는 hidden state들의 묶음.\n",
        "*   `h_n`: 모든 sequence를 거치고 나온 마지막 hidden state.\n",
        "\n",
        "torch의 RNN 문서를 참조하여서, ``batch_emb``변수를 rnn에 input으로 넣어보세요.\n",
        "나온 결과의 shape도 출력해보세요. "
      ],
      "metadata": {
        "id": "qEA7MDSl4NGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, L, H_in = batch_emb.shape\n",
        "hidden_states, h_n = rnn(batch_emb, h_0)"
      ],
      "metadata": {
        "id": "g92gSpofNeTE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states, h_n = rnn(batch_emb, h_0)"
      ],
      "metadata": {
        "id": "kD5YWd59OJ87"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states[:,-1,:], h_n.reshape(10, 1, 512)"
      ],
      "metadata": {
        "id": "1-mZdR3XOJ1W",
        "outputId": "33fe3d77-27a7-4e4a-b043-657d25e0fe4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.4969, -0.4177, -0.4530,  ..., -0.7763,  0.0924,  0.4577],\n",
              "         [ 0.7106, -0.1318,  0.2029,  ..., -0.0729,  0.6004,  0.5190],\n",
              "         [ 0.6978, -0.0470,  0.2689,  ..., -0.0362,  0.4559,  0.4272],\n",
              "         ...,\n",
              "         [ 0.8446,  0.0419,  0.0241,  ...,  0.1093,  0.4085,  0.5593],\n",
              "         [ 0.8445,  0.0419,  0.0241,  ...,  0.1093,  0.4085,  0.5593],\n",
              "         [ 0.8446,  0.0419,  0.0241,  ...,  0.1093,  0.4085,  0.5593]],\n",
              "        grad_fn=<SliceBackward0>),\n",
              " tensor([[[ 0.4969, -0.4177, -0.4530,  ..., -0.7763,  0.0924,  0.4577]],\n",
              " \n",
              "         [[ 0.7106, -0.1318,  0.2029,  ..., -0.0729,  0.6004,  0.5190]],\n",
              " \n",
              "         [[ 0.6978, -0.0470,  0.2689,  ..., -0.0362,  0.4559,  0.4272]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ 0.8446,  0.0419,  0.0241,  ...,  0.1093,  0.4085,  0.5593]],\n",
              " \n",
              "         [[ 0.8445,  0.0419,  0.0241,  ...,  0.1093,  0.4085,  0.5593]],\n",
              " \n",
              "         [[ 0.8446,  0.0419,  0.0241,  ...,  0.1093,  0.4085,  0.5593]]],\n",
              "        grad_fn=<ReshapeAliasBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막 hidden state를 이용하여 text classification task에 적용할 수 있습니다."
      ],
      "metadata": {
        "id": "xOo2Xy744hT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "classification_layer = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "# C: number of classes\n",
        "output = classification_layer(h_n.squeeze(0))  # (1, B, d_h) => (B, C)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "KtdaqR0W4PdY",
        "outputId": "29e2b9b5-9486-4402-ec4d-f6ff3464cfe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 time step에 대한 hidden state를 이용하여 token-level의 task를 수행할 수도 있습니다."
      ],
      "metadata": {
        "id": "K9cbRbw44kXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "entity_layer = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "# C: number of classes\n",
        "output = entity_layer(hidden_states)  # (L, B, d_h) => (L, B, C)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "yv-F7KLw4kt8",
        "outputId": "325d4a53-8e34-470a-8af5-b7e1c8d30867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 20, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM 활용법**"
      ],
      "metadata": {
        "id": "inHpHVXz44T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM에선 cell state가 추가됩니다.  \n",
        "Cell state의 shape는 hidden state의 그것과 동일합니다.\n",
        "\n",
        "- batch_emb 변수를 LSTM에 넣을 예정입니다.\n",
        "- torch 공식 문서를 참조하여, LSTM 모델을 정의해보세요. \n",
        "- input size는 어떻게 되어야 하나요?"
      ],
      "metadata": {
        "id": "kQGkzE7c485n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_dirs = 1\n",
        "\n",
        "## TODO ##\n",
        "lstm = nn.LSTM(\n",
        "    input_size = embedding_size,\n",
        "    hidden_size = hidden_size,\n",
        "    num_layers = num_layers,\n",
        "    bidirectional = True if num_dirs > 1 else False,\n",
        "    batch_first = True\n",
        ")\n",
        "\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\n",
        "c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"
      ],
      "metadata": {
        "id": "VeIwgX_k45oG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch의 LSTM 문서를 참조하여서, ``batch_emb``변수를 rnn에 input으로 넣어보세요.\n",
        "나온 결과의 shape도 출력해보세요. "
      ],
      "metadata": {
        "id": "-Oy7ZVdycFfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO ##\n",
        "output, (h_n, c_n) =lstm(batch_emb)"
      ],
      "metadata": {
        "id": "-Z9E4vG65Bbx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape, h_n.shape, c_n.shape\n",
        "\n",
        "\n",
        "output[:, -1,:] #output의 제일 뒷부분이 필요할 경우"
      ],
      "metadata": {
        "id": "wp2xklysOpze",
        "outputId": "a395a6c1-9de9-4f02-c7b2-54dcd78fde14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0322,  0.1457, -0.0418,  ..., -0.0330,  0.0359, -0.0761],\n",
              "        [ 0.1041, -0.0197, -0.1661,  ...,  0.2366,  0.0287, -0.1752],\n",
              "        [ 0.1793, -0.0448, -0.1474,  ...,  0.2302, -0.1761, -0.1182],\n",
              "        ...,\n",
              "        [ 0.1961, -0.1456, -0.1974,  ...,  0.2676, -0.1352, -0.2442],\n",
              "        [ 0.1963, -0.1457, -0.1973,  ...,  0.2675, -0.1362, -0.2441],\n",
              "        [ 0.1959, -0.1450, -0.1975,  ...,  0.2674, -0.1352, -0.2447]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRU 사용**"
      ],
      "metadata": {
        "id": "JcShheOD5RRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \n",
        "GRU를 이용하여 LM task를 수행해봅시다."
      ],
      "metadata": {
        "id": "ughudT3z5TgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru = nn.GRU(\n",
        "    input_size=embedding_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=True if num_dirs > 1 else False\n",
        ")"
      ],
      "metadata": {
        "id": "hoaaK6Gn5LLK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = nn.Linear(hidden_size, vocab_size)"
      ],
      "metadata": {
        "id": "cPqE9iKP6zFX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_id = batch.transpose(0, 1)[0, :]  # (B)\n",
        "hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"
      ],
      "metadata": {
        "id": "VY3330vm6025"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(max_len):\n",
        "  input_emb = embedding(input_id).unsqueeze(0)  # (1, B, d_w)\n",
        "  output, hidden = gru(input_emb, hidden)  # output: (1, B, d_h), hidden: (1, B, d_h)\n",
        "\n",
        "  # V: vocab size\n",
        "  output = output_layer(output)  # (1, B, V)\n",
        "  probs, top_id = torch.max(output, dim=-1)  # probs: (1, B), top_id: (1, B)\n",
        "\n",
        "  print(\"*\" * 50)\n",
        "  print(f\"Time step: {t}\")\n",
        "  print(output.shape)\n",
        "  print(probs.shape)\n",
        "  print(top_id.shape)\n",
        "\n",
        "  input_id = top_id.squeeze(0)  # (B)"
      ],
      "metadata": {
        "id": "LxKH3fqc7A_1",
        "outputId": "fd352cea-ff37-4e32-d366-5f8ddfaec843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "Time step: 0\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 1\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 2\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 3\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 4\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 5\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 6\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 7\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 8\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 9\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 10\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 11\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 12\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 13\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 14\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 15\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 16\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 17\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 18\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 19\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **양방향 및 여러 layer 사용**"
      ],
      "metadata": {
        "id": "a6xnrQ5v7WB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다.\n"
      ],
      "metadata": {
        "id": "W6HEakT87ZvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 2\n",
        "num_dirs = 2\n",
        "dropout=0.1\n",
        "\n",
        "gru = nn.GRU(\n",
        "    input_size=embedding_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    dropout=dropout,\n",
        "    bidirectional=True if num_dirs > 1 else False\n",
        ")"
      ],
      "metadata": {
        "id": "rsY16YFF7BaZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."
      ],
      "metadata": {
        "id": "3RBq941o7eja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\n",
        "\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
        "\n",
        "packed_outputs, h_n = gru(packed_batch, h_0)\n",
        "print(packed_outputs)\n",
        "print(packed_outputs[0].shape)\n",
        "print(h_n.shape)"
      ],
      "metadata": {
        "id": "vnX1sVRV7d6m",
        "outputId": "1d624d3d-7338-4f58-c99a-d2fb38b44444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequence(data=tensor([[-0.0470, -0.1891,  0.1556,  ..., -0.0798,  0.1125, -0.2541],\n",
            "        [ 0.0282, -0.0565,  0.0718,  ..., -0.1477,  0.1251, -0.0179],\n",
            "        [-0.0677,  0.1353, -0.0156,  ...,  0.0016,  0.0121,  0.0860],\n",
            "        ...,\n",
            "        [-0.2320, -0.1410,  0.0334,  ..., -0.1367,  0.0985, -0.0995],\n",
            "        [-0.0760, -0.0868,  0.0881,  ..., -0.1147, -0.1219, -0.0702],\n",
            "        [-0.0783, -0.2514,  0.0836,  ..., -0.1202, -0.0884, -0.0358]],\n",
            "       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 1024])\n",
            "torch.Size([4, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
        "\n",
        "print(outputs.shape)  # (L, B, num_dirs*d_h)\n",
        "print(output_lens)"
      ],
      "metadata": {
        "id": "68tacMlZ7lhJ",
        "outputId": "08252efb-9292-4264-9680-e2e99ab1f4cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 10, 1024])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각의 결과물의 shape는 다음과 같습니다.\n",
        "\n",
        "`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \n",
        "`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"
      ],
      "metadata": {
        "id": "0fEA75iy7sRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = h_n.shape[1]\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"
      ],
      "metadata": {
        "id": "BtY4oBJn7pJb",
        "outputId": "ee21ca84-20b3-401d-e671-786d01da6fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.2724, -0.2822, -0.1090,  ...,  0.2506, -0.3323,  0.0265],\n",
            "          [-0.2999,  0.0186,  0.3451,  ..., -0.0824, -0.2832, -0.4517],\n",
            "          [ 0.0200, -0.2409, -0.2098,  ...,  0.2035, -0.0612, -0.2836],\n",
            "          ...,\n",
            "          [-0.0880, -0.3622, -0.1911,  ..., -0.0555,  0.1137, -0.2440],\n",
            "          [ 0.0398, -0.1484,  0.1893,  ..., -0.4380, -0.0956, -0.4010],\n",
            "          [-0.1810, -0.2444,  0.0497,  ...,  0.0760,  0.0066,  0.0766]],\n",
            "\n",
            "         [[-0.2194,  0.0906,  0.1520,  ...,  0.2620, -0.1005, -0.1851],\n",
            "          [ 0.3343, -0.1336, -0.1695,  ..., -0.3477,  0.0234,  0.1033],\n",
            "          [ 0.0155, -0.2534,  0.1353,  ...,  0.2593, -0.0909, -0.0084],\n",
            "          ...,\n",
            "          [-0.3252,  0.3058, -0.2947,  ...,  0.4062,  0.2628,  0.0749],\n",
            "          [ 0.4008,  0.2373,  0.5453,  ..., -0.2083, -0.1086, -0.3592],\n",
            "          [-0.1681,  0.5277, -0.1958,  ..., -0.1763, -0.4486,  0.2234]]],\n",
            "\n",
            "\n",
            "        [[[-0.0783, -0.2514,  0.0836,  ...,  0.1483, -0.0920,  0.2808],\n",
            "          [-0.0704, -0.1932, -0.0149,  ...,  0.1023, -0.0674, -0.1817],\n",
            "          [-0.2320, -0.1410,  0.0334,  ..., -0.1067,  0.1407, -0.0899],\n",
            "          ...,\n",
            "          [ 0.0697,  0.0118, -0.0424,  ..., -0.0640,  0.0489, -0.1018],\n",
            "          [-0.0154,  0.0039, -0.1908,  ..., -0.0214,  0.0361, -0.1024],\n",
            "          [-0.0731,  0.0270, -0.0970,  ...,  0.0809, -0.0728, -0.0250]],\n",
            "\n",
            "         [[ 0.0538,  0.1574,  0.0107,  ..., -0.0798,  0.1125, -0.2541],\n",
            "          [-0.0370,  0.1343, -0.0698,  ..., -0.1477,  0.1251, -0.0179],\n",
            "          [-0.0362,  0.1517,  0.0434,  ...,  0.0016,  0.0121,  0.0860],\n",
            "          ...,\n",
            "          [ 0.0021,  0.1291, -0.0238,  ..., -0.2451,  0.1434, -0.0908],\n",
            "          [ 0.0230,  0.2344, -0.0398,  ..., -0.0805,  0.1245, -0.0253],\n",
            "          [ 0.2318,  0.0208,  0.1560,  ..., -0.1697, -0.0644,  0.2164]]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([2, 2, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7abJ7ClySUnj"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}